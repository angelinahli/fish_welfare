{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fish Welfare Project\n",
    "## Part 1: Scraping the DB\n",
    "\n",
    "* Author: Angelina Li\n",
    "* Date: 2019/09/10\n",
    "* Description: This project is an attempt to collect information presented on the [FishEthoBase](http://fishethobase.net/db/) and make that data more navigatable to interested users.\n",
    "\n",
    "## Notebook tasks\n",
    "1. Grab a list of all the fish catalogued on the FishEthoBase.\n",
    "2. For each fish, check if they have a short profile.\n",
    "3. Grab the short profile table for each fish.\n",
    "4. Grab the picture and summary information per species.\n",
    "\n",
    "Ideal variables to collect per species:\n",
    "* English name\n",
    "* Latin name\n",
    "* Summary link\n",
    "* Short profile link\n",
    "* Summary description\n",
    "* Image link\n",
    "* Home range, depth range, migration, reproduction, etc. etc. likelihood / potential / certainty\n",
    "* FishEthoScore per section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import requests\n",
    "import sys\n",
    "import time\n",
    "import urllib\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are relative paths - running the script from a different location may produce surprising results.\n",
    "MAIN_DIR = \"..\"\n",
    "DATA_DIR = os.path.join(MAIN_DIR, \"data\")\n",
    "\n",
    "FISH_BASE_ADDR = \"http://fishethobase.net\"\n",
    "DB_ADDR = FISH_BASE_ADDR + \"/db\"\n",
    "S_PAUSE = 2 # how many seconds to pause in between requests\n",
    "\n",
    "REQ_SUCCESS = 200 # success status code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url_address, pause_secs=S_PAUSE):\n",
    "    page = requests.get(url_address)\n",
    "    if page.status_code != REQ_SUCCESS:\n",
    "        print(\"Couldn't load content on this page:\", url_address)\n",
    "        return\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    time.sleep(pause_secs)\n",
    "    print(\"Loaded page:\", url_address)\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded page: http://fishethobase.net/db\n",
      "<!DOCTYPE html>\n",
      "<!--[if lt IE 7]>      <html class=\"no-js lt-ie9 lt-ie8 lt-ie7\"> <![endif]-->\n",
      "<!--[if IE 7]>         <html class=\"no-js lt-ie9 lt-ie8\"> <![endif]-->\n",
      "<!--[if IE 8]>         <html class=\"no-js lt-ie9\"> <![endif]-->\n",
      "<!--[if gt IE 8]><!-->\n",
      "<html class=\"no-js\">\n",
      " <!--<![endif]-->\n",
      " <html>\n",
      "  <head>\n",
      "   <meta charset=\"utf-8\"/>\n",
      "   <meta content=\"IE=edge,chrome=1\" http-equiv=\"X-UA-Compatible\"/\n"
     ]
    }
   ],
   "source": [
    "db_soup = get_soup(DB_ADDR)\n",
    "print(db_soup.prettify()[:400])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Grab a list of all the fish catalogued on the FishEthoBase.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ul class=\"speciestree-sub\">\n",
      " <li>\n",
      "  <a class=\"speciestree-order\" href=\"#\" onclick=\"return false;\">\n",
      "   Cephalopoda (Cephalopoda)\n",
      "  </a>\n",
      "  <ul>\n",
      "   <li>\n",
      "    <a class=\"speciestree-intern speciestree-short\" href=\"/db/28/\" style=\"\" target=\"_self\" title=\"Short profile\">\n",
      "     <i>\n",
      "      Octopus vulgaris\n",
      "     </i>\n",
      "     (Common octopus)\n",
      "    </a>\n",
      "   </li>\n",
      "  </ul>\n",
      " </li>\n",
      " <li>\n",
      "  <a class=\"speciestree-order\" h\n"
     ]
    }
   ],
   "source": [
    "species_tree = db_soup.find(class_=\"speciestree-sub\")\n",
    "print(species_tree.prettify()[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num species: 44 \n",
      "\n",
      "HTML Tree:\n",
      "<a class=\"speciestree-intern speciestree-short\" href=\"/db/28/\" style=\"\" target=\"_self\" title=\"Short profile\">\n",
      " <i>\n",
      "  Octopus vulgaris\n",
      " </i>\n",
      " (Common octopus)\n",
      "</a>\n"
     ]
    }
   ],
   "source": [
    "# seems like each fish is categorized as a 'speciestree-intern'. Let's take a look at these.\n",
    "species_soups = species_tree.find_all(attrs={\"class\": \"speciestree-intern\"})\n",
    "print(\"Num species:\", len(species_soups), \"\\n\")\n",
    "print(\"HTML Tree:\\n\" + species_soups[0].prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary_addr': 'http://fishethobase.net/db/28/',\n",
       " 'latin_name': 'Octopus vulgaris',\n",
       " 'english_name': 'Common octopus',\n",
       " 'key': 'commonoctopus'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_link_pattern = re.compile(\"/db/[0-9]+/?\")\n",
    "name_pattern = re.compile(\"[A-Za-z, ]+\\([A-Za-z ()]+\\)\")\n",
    "\n",
    "def get_species_dict(species_soup):\n",
    "    raw_addr = species_soup.get(\"href\")\n",
    "    if not summary_link_pattern.match(raw_addr):\n",
    "        print(\"Unexpected raw address:\", raw_addr)\n",
    "        return\n",
    "    summary_addr = FISH_BASE_ADDR + raw_addr\n",
    "    \n",
    "    name_text = species_soup.get_text()\n",
    "    if not name_pattern.match(name_text):\n",
    "        print(\"Unexpected name format:\", name_text)\n",
    "        return\n",
    "    latin_name = name_text.split(\"(\")[0].strip()\n",
    "    english_name = name_text.split(\"(\", 1)[1][:-1].strip()\n",
    "    \n",
    "    return dict(\n",
    "        summary_addr=summary_addr,\n",
    "        latin_name=latin_name,\n",
    "        english_name=english_name,\n",
    "        key=re.sub(\"\\W\", \"\", english_name).lower()\n",
    "    )\n",
    "\n",
    "get_species_dict(species_soups[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary_addr': 'http://fishethobase.net/db/21/',\n",
       " 'latin_name': 'Litopenaeus vannamei',\n",
       " 'english_name': 'Pacific whiteleg shrimp',\n",
       " 'key': 'pacificwhitelegshrimp'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species = list(map(get_species_dict, species_soups))\n",
    "\n",
    "species[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_addr': 'http://fishethobase.net/db/28/',\n",
       "  'latin_name': 'Octopus vulgaris',\n",
       "  'english_name': 'Common octopus',\n",
       "  'key': 'commonoctopus'},\n",
       " {'summary_addr': 'http://fishethobase.net/db/21/',\n",
       "  'latin_name': 'Litopenaeus vannamei',\n",
       "  'english_name': 'Pacific whiteleg shrimp',\n",
       "  'key': 'pacificwhitelegshrimp'},\n",
       " {'summary_addr': 'http://fishethobase.net/db/34/',\n",
       "  'latin_name': 'Penaeus monodon',\n",
       "  'english_name': 'Giant tiger prawn (Black tiger)',\n",
       "  'key': 'gianttigerprawnblacktiger'},\n",
       " {'summary_addr': 'http://fishethobase.net/db/2/',\n",
       "  'latin_name': 'Acipenser baerii',\n",
       "  'english_name': 'Siberian sturgeon',\n",
       "  'key': 'siberiansturgeon'},\n",
       " {'summary_addr': 'http://fishethobase.net/db/3/',\n",
       "  'latin_name': 'Acipenser gueldenstaedtii',\n",
       "  'english_name': 'Russian sturgeon',\n",
       "  'key': 'russiansturgeon'},\n",
       " {'summary_addr': 'http://fishethobase.net/db/4/',\n",
       "  'latin_name': 'Acipenser naccarii',\n",
       "  'english_name': 'Adriatic sturgeon',\n",
       "  'key': 'adriaticsturgeon'},\n",
       " {'summary_addr': 'http://fishethobase.net/db/6/',\n",
       "  'latin_name': 'Acipenser ruthenus',\n",
       "  'english_name': 'Sterlet sturgeon',\n",
       "  'key': 'sterletsturgeon'},\n",
       " {'summary_addr': 'http://fishethobase.net/db/5/',\n",
       "  'latin_name': 'Acipenser stellatus',\n",
       "  'english_name': 'Stellate sturgeon',\n",
       "  'key': 'stellatesturgeon'},\n",
       " {'summary_addr': 'http://fishethobase.net/db/7/',\n",
       "  'latin_name': 'Acipenser transmontanus',\n",
       "  'english_name': 'White sturgeon',\n",
       "  'key': 'whitesturgeon'},\n",
       " {'summary_addr': 'http://fishethobase.net/db/53/',\n",
       "  'latin_name': 'BAEyNAC, NACxBAE',\n",
       "  'english_name': 'Hybrid sturgeon',\n",
       "  'key': 'hybridsturgeon'},\n",
       " {'summary_addr': 'http://fishethobase.net/db/61/',\n",
       "  'latin_name': 'Chromobotia macracanthus',\n",
       "  'english_name': 'Clown loach',\n",
       "  'key': 'clownloach'},\n",
       " {'summary_addr': 'http://fishethobase.net/db/11/',\n",
       "  'latin_name': 'Ctenopharyngodon idella',\n",
       "  'english_name': 'Grass carp',\n",
       "  'key': 'grasscarp'},\n",
       " {'summary_addr': 'http://fishethobase.net/db/12/',\n",
       "  'latin_name': 'Cyprinus carpio',\n",
       "  'english_name': 'Common carp',\n",
       "  'key': 'commoncarp'},\n",
       " {'summary_addr': 'http://fishethobase.net/db/17/',\n",
       "  'latin_name': 'Gadus morhua',\n",
       "  'english_name': 'Atlantic cod',\n",
       "  'key': 'atlanticcod'},\n",
       " {'summary_addr': 'http://fishethobase.net/db/22/',\n",
       "  'latin_name': 'Lota lota',\n",
       "  'english_name': 'Burbot',\n",
       "  'key': 'burbot'},\n",
       " {'summary_addr': 'http://fishethobase.net/db/26/',\n",
       "  'latin_name': 'Mugil cephalus',\n",
       "  'english_name': 'Striped mullet',\n",
       "  'key': 'stripedmullet'},\n",
       " {'summary_addr': 'http://fishethobase.net/db/45/',\n",
       "  'latin_name': 'Seriola dumerili',\n",
       "  'english_name': 'Greater amberjack',\n",
       "  'key': 'greateramberjack'},\n",
       " {'summary_addr': 'http://fishethobase.net/db/46/',\n",
       "  'latin_name': 'Seriola lalandi',\n",
       "  'english_name': 'Yellowtail amberjack',\n",
       "  'key': 'yellowtailamberjack'},\n",
       " {'summary_addr': 'http://fishethobase.net/db/31/',\n",
       "  'latin_name': 'Oreochromis niloticus',\n",
       "  'english_name': 'Nile tilapia',\n",
       "  'key': 'niletilapia'},\n",
       " {'summary_addr': 'http://fishethobase.net/db/20/',\n",
       "  'latin_name': 'Lates calcarifer',\n",
       "  'english_name': 'Barramundi',\n",
       "  'key': 'barramundi'},\n",
       " {'summary_addr': 'http://fishethobase.net/db/14/',\n",
       "  'latin_name': 'Dicentrachus labrax',\n",
       "  'english_name': 'European seabass',\n",
       "  'key': 'europeanseabass'},\n",
       " {'summary_addr': 'http://fishethobase.net/db/35/',\n",
       "  'latin_name': 'Perca fluviatilis',\n",
       "  'english_name': 'European perch',\n",
       "  'key': 'europeanperch'},\n",
       " {'summary_addr': 'http://fishethobase.net/db/42/',\n",
       "  'latin_name': 'Sander lucioperca',\n",
       "  'english_name': 'Pikeperch',\n",
       "  'key': 'pikeperch'},\n",
       " {'summary_addr': 'http://fishethobase.net/db/13/',\n",
       "  'latin_name': 'Dentex dentex',\n",
       "  'english_name': 'Common Dentex',\n",
       "  'key': 'commondentex'},\n",
       " {'summary_addr': 'http://fishethobase.net/db/36/',\n",
       "  'latin_name': 'Polyprion americanus',\n",
       "  'english_name': 'Wreckfish',\n",
       "  'key': 'wreckfish'},\n",
       " {'summary_addr': 'http://fishethobase.net/db/38/',\n",
       "  'latin_name': 'Rachycentron canadum',\n",
       "  'english_name': 'Cobia',\n",
       "  'key': 'cobia'},\n",
       " {'summary_addr': 'http://fishethobase.net/db/8/',\n",
       "  'latin_name': 'Argyrosomus regius',\n",
       "  'english_name': 'Meagre',\n",
       "  'key': 'meagre'},\n",
       " {'summary_addr': 'http://fishethobase.net/db/50/',\n",
       "  'latin_name': 'Thunnus maccoyii',\n",
       "  'english_name': 'Southern bluefin tuna',\n",
       "  'key': 'southernbluefintuna'},\n",
       " {'summary_addr': 'http://fishethobase.net/db/16/',\n",
       "  'latin_name': 'Epinephelus malabaricus',\n",
       "  'english_name': 'Malabar Grouper',\n",
       "  'key': 'malabargrouper'},\n",
       " {'summary_addr': 'http://fishethobase.net/db/15/',\n",
       "  'latin_name': 'Diplodus puntazzo',\n",
       "  'english_name': 'Sharpsnout Seabream',\n",
       "  'key': 'sharpsnoutseabream'},\n",
       " {'summary_addr': 'http://fishethobase.net/db/32/',\n",
       "  'latin_name': 'Pagrus pagrus',\n",
       "  'english_name': 'Red Porgy',\n",
       "  'key': 'redporgy'},\n",
       " {'summary_addr': 'http://fishethobase.net/db/49/',\n",
       "  'latin_name': 'Sparus aurata',\n",
       "  'english_name': 'Gilthead seabream',\n",
       "  'key': 'giltheadseabream'},\n",
       " {'summary_addr': 'http://fishethobase.net/db/18/',\n",
       "  'latin_name': 'Hippoglossus hippoglossus',\n",
       "  'english_name': 'Atlantic halibut',\n",
       "  'key': 'atlantichalibut'},\n",
       " {'summary_addr': 'http://fishethobase.net/db/43/',\n",
       "  'latin_name': 'Scophthalmus maximus',\n",
       "  'english_name': 'Turbot',\n",
       "  'key': 'turbot'},\n",
       " {'summary_addr': 'http://fishethobase.net/db/48/',\n",
       "  'latin_name': 'Solea senegalensis',\n",
       "  'english_name': 'Senegalese sole',\n",
       "  'key': 'senegalesesole'},\n",
       " {'summary_addr': 'http://fishethobase.net/db/47/',\n",
       "  'latin_name': 'Solea solea',\n",
       "  'english_name': 'Dover sole',\n",
       "  'key': 'doversole'},\n",
       " {'summary_addr': 'http://fishethobase.net/db/29/',\n",
       "  'latin_name': 'Oncorhynchus masou',\n",
       "  'english_name': 'Cherry salmon',\n",
       "  'key': 'cherrysalmon'},\n",
       " {'summary_addr': 'http://fishethobase.net/db/30/',\n",
       "  'latin_name': 'Oncorhynchus mykiss',\n",
       "  'english_name': 'Rainbow trout',\n",
       "  'key': 'rainbowtrout'},\n",
       " {'summary_addr': 'http://fishethobase.net/db/1/',\n",
       "  'latin_name': 'Salmo salar',\n",
       "  'english_name': 'Atlantic salmon',\n",
       "  'key': 'atlanticsalmon'},\n",
       " {'summary_addr': 'http://fishethobase.net/db/40/',\n",
       "  'latin_name': 'Salvelinus alpinus alpinus',\n",
       "  'english_name': 'Arctic char',\n",
       "  'key': 'arcticchar'},\n",
       " {'summary_addr': 'http://fishethobase.net/db/41/',\n",
       "  'latin_name': 'Salvelinus fontinalis',\n",
       "  'english_name': 'Brook trout',\n",
       "  'key': 'brooktrout'},\n",
       " {'summary_addr': 'http://fishethobase.net/db/51/',\n",
       "  'latin_name': 'Thymallus thymallus',\n",
       "  'english_name': 'Grayling',\n",
       "  'key': 'grayling'},\n",
       " {'summary_addr': 'http://fishethobase.net/db/10/',\n",
       "  'latin_name': 'Clarias gariepinus',\n",
       "  'english_name': 'African sharptooth catfish',\n",
       "  'key': 'africansharptoothcatfish'},\n",
       " {'summary_addr': 'http://fishethobase.net/db/33/',\n",
       "  'latin_name': 'Pangasianodon hypophthalmus',\n",
       "  'english_name': 'Pangasius',\n",
       "  'key': 'pangasius'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# species: 44\n",
      "# unique keys: 44\n"
     ]
    }
   ],
   "source": [
    "print(\"# species:\", len(species))\n",
    "print(\"# unique keys:\", len(set([dct[\"key\"] for dct in species])) ) # checking keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Grab the picture and summary information per species.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_species_dict_with_summary(species_dict):\n",
    "    return_dict = species_dict.copy() # shallow copy is sufficient for these dicts; \n",
    "                                      # the prev dicts will also be discarded\n",
    "    soup = get_soup(species_dict[\"summary_addr\"])\n",
    "\n",
    "    picture = soup.find(id=\"species_picture\")\n",
    "    if picture:\n",
    "        img = picture.find(\"img\")\n",
    "        img_addr = FISH_BASE_ADDR + \"/\" + img[\"src\"].lstrip(\"/\")\n",
    "        download_filename = \"{fn}.{ext}\".format(fn=return_dict[\"key\"], ext=img_addr.split(\".\")[-1]) # totally hacky\n",
    "        download_addr = os.path.join(DATA_DIR, \"images\", download_filename)\n",
    "        \n",
    "        urllib.request.urlretrieve(img_addr, download_addr)\n",
    "        \n",
    "        return_dict[\"image_filename\"] = download_filename\n",
    "        print(\"Downloaded photo:\", download_addr)\n",
    "    \n",
    "    summary = soup.find(class_=\"feb-content-box\")\n",
    "    if summary:\n",
    "        all_text = summary.get_text()\n",
    "        summary_text = all_text.strip(\"\\n\").split(\"\\n\", 1)[0].replace(\"\\xa0\", \" \")\n",
    "        return_dict[\"summary_text\"] = summary_text\n",
    "    \n",
    "    else:\n",
    "        print(\"**No summary found!**\")\n",
    "\n",
    "    return return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded page: http://fishethobase.net/db/28/\n",
      "\n",
      "Loaded page: http://fishethobase.net/db/21/\n",
      "\n",
      "Loaded page: http://fishethobase.net/db/34/\n",
      "Downloaded photo: ..\\data\\images\\gianttigerprawnblacktiger.jpg\n",
      "\n",
      "Loaded page: http://fishethobase.net/db/2/\n",
      "Downloaded photo: ..\\data\\images\\siberiansturgeon.jpg\n"
     ]
    }
   ],
   "source": [
    "# shortened testing snippet to reduce runtime\n",
    "species_with_summaries_shortened = list(map(get_species_dict_with_summary, species[:4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_addr': 'http://fishethobase.net/db/28/',\n",
       "  'latin_name': 'Octopus vulgaris',\n",
       "  'english_name': 'Common octopus',\n",
       "  'key': 'commonoctopus',\n",
       "  'summary_text': 'Octopus vulgaris has recently aroused much interest in aquaculture, considered suitable for large-scale production given its commercial value, its fecundity, rapid growth, high protein content, and high feed conversion rate. The main problem, however, is the high mortality rate observed during paralarval rearing, making successful juvenile settlement still very difficult to achieve. Unfortunately, despite the high knowledge on the biology and ethology of this species, there are many other aspects to be solved from a welfare perspective. For instance, the current farming systems result in high stress in O. vulgaris due to spatial constraint, high densities and sociability, which consequently increase aggression (cannibalism and autophagy) at different life stages. In addition, octopus skin is particularly sensitive and can be easily damaged during handling, transportation or stressful confinement conditions. A humane slaughtering protocol is not yet established, since the nature and degree of any suffering during current practices are unknown. O. vulgaris appears capable of experiencing pain and suffering, exhibits cognitive complexity and sophisticated behavioural patterns which can be interpreted and serve as indicator of the welfare status.'},\n",
       " {'summary_addr': 'http://fishethobase.net/db/21/',\n",
       "  'latin_name': 'Litopenaeus vannamei',\n",
       "  'english_name': 'Pacific whiteleg shrimp',\n",
       "  'key': 'pacificwhitelegshrimp',\n",
       "  'summary_text': 'Habitat and development'},\n",
       " {'summary_addr': 'http://fishethobase.net/db/34/',\n",
       "  'latin_name': 'Penaeus monodon',\n",
       "  'english_name': 'Giant tiger prawn (Black tiger)',\n",
       "  'key': 'gianttigerprawnblacktiger',\n",
       "  'image_filename': 'gianttigerprawnblacktiger.jpg',\n",
       "  'summary_text': 'Penaeus monodon is one of the most cultivated crustaceans worldwide, with over 500,000 tonnes harvested every year, and the most important traded aquaculture commodity in Asia. Despite being reared for over a century and fairly well studied, many of its biological needs are disregarded in farming, such as spatial requirements and reproductive conditions. In fact, spawning techniques majorly include uni- or bilateral ablation of eyestalks, even though there is evidence that this species spawns without direct manipulation. Stress is also an issue that should be tackled, as poor farming conditions may cause stress and evoke high sensitivity to infections. A slaughter protocol should also be implemented, as stunning and slaughtering are normally performed by immersion in icewater.'},\n",
       " {'summary_addr': 'http://fishethobase.net/db/2/',\n",
       "  'latin_name': 'Acipenser baerii',\n",
       "  'english_name': 'Siberian sturgeon',\n",
       "  'key': 'siberiansturgeon',\n",
       "  'image_filename': 'siberiansturgeon.jpg',\n",
       "  'summary_text': 'Acipenser baerii, an endangered species according to the IUCN redlist, has been farmed for over a century, but only recently the full life cycle has been successfully closed in aquaculture. Sturgeons are mostly reared for caviar, and while its production started in the former USSR, A. baerii production is now present in Belgium, China, Italy, Germany, Hungary, Poland, Spain, Switzlerland and the United States of America. However, there are many aspects of welfare that are being overlooked: usual rearing tanks are too small, spawning induction is highly invasive, it requires proper substrate in all stages of its life cycle, and the establishment of a humane slaughter protocol is still missing. Although some effort is being undertaken, fish components are still present in the feed. Many aspects of its biology remain unclear and require further investigation. '}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "species_with_summaries_shortened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'summary_addr': 'http://fishethobase.net/db/21/',\n",
       "  'latin_name': 'Litopenaeus vannamei',\n",
       "  'english_name': 'Pacific whiteleg shrimp',\n",
       "  'key': 'pacificwhitelegshrimp',\n",
       "  'summary_text': 'Habitat and development'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# some of the summaries appear too short, or incorrect. Let's try to locate those summaries.\n",
    "\n",
    "odd_summaries = [s for s in species_with_summaries_shortened if not \"summary_text\" in s or len(s[\"summary_text\"]) < 100]\n",
    "odd_summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for most of the above, it looks like I've pulled the wrong summary (Except for the one that has no short profile).\n",
    "# To be safe, let's pull the 'general remarks' tab for each species too, and compare what is happening."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. For each fish, check if they have a short profile. 3. Grab the short profile table for each fish. (5. Grab the general remarks for each fish.)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_species_with_short_profiles(species_dict):\n",
    "    return_dict = species_dict.copy() # shallow copy is sufficient for these dicts; \n",
    "                                      # the prev dicts will also be discarded\n",
    "    sp_address = species_dict[\"summary_addr\"] + \"shortprofile/\"\n",
    "    soup = get_soup(sp_address)\n",
    "    if not soup:\n",
    "        return\n",
    "    return_dict[\"short_profile_addr\"] = sp_address\n",
    "    \n",
    "    sp_table = soup.find(\"table\", attrs={\"class\": \"shortprofile\"})\n",
    "    if sp_table:\n",
    "        sp_table_rows = sp_table.find_all(\"tr\")\n",
    "\n",
    "        all_data = {}\n",
    "        headings = [\"likelihood\", \"potential\", \"certainty\"] # should be a way of validating this\n",
    "        for row in sp_table_rows[1:-1]:            \n",
    "            columns = row.find_all(\"td\")[1:]\n",
    "            criteria = columns[0].get_text()\n",
    "            values = [ col[\"class\"][0] for col in columns[1:] ]\n",
    "            row_data = dict(zip(headings, values))\n",
    "            all_data[criteria] = row_data\n",
    "        \n",
    "        score_columns = sp_table_rows[-1].find_all(\"td\")\n",
    "        score_criteria = score_columns[0].get_text()\n",
    "        total_scores = map(float, [ col.get_text() for col in score_columns[1:] ])\n",
    "        all_data[score_criteria] = dict(zip(headings, total_scores))\n",
    "\n",
    "        return_dict[\"etho_scores\"] = all_data\n",
    "\n",
    "    return return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded page: http://fishethobase.net/db/28/shortprofile/\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'summary_addr': 'http://fishethobase.net/db/28/',\n",
       " 'latin_name': 'Octopus vulgaris',\n",
       " 'english_name': 'Common octopus',\n",
       " 'key': 'commonoctopus',\n",
       " 'summary_text': 'Octopus vulgaris has recently aroused much interest in aquaculture, considered suitable for large-scale production given its commercial value, its fecundity, rapid growth, high protein content, and high feed conversion rate. The main problem, however, is the high mortality rate observed during paralarval rearing, making successful juvenile settlement still very difficult to achieve. Unfortunately, despite the high knowledge on the biology and ethology of this species, there are many other aspects to be solved from a welfare perspective. For instance, the current farming systems result in high stress in O. vulgaris due to spatial constraint, high densities and sociability, which consequently increase aggression (cannibalism and autophagy) at different life stages. In addition, octopus skin is particularly sensitive and can be easily damaged during handling, transportation or stressful confinement conditions. A humane slaughtering protocol is not yet established, since the nature and degree of any suffering during current practices are unknown. O. vulgaris appears capable of experiencing pain and suffering, exhibits cognitive complexity and sophisticated behavioural patterns which can be interpreted and serve as indicator of the welfare status.',\n",
       " 'short_profile_addr': 'http://fishethobase.net/db/28/shortprofile/',\n",
       " 'etho_scores': {'Home range': {'likelihood': 'low',\n",
       "   'potential': 'low',\n",
       "   'certainty': 'high'},\n",
       "  'Depth range': {'likelihood': 'low',\n",
       "   'potential': 'middle',\n",
       "   'certainty': 'high'},\n",
       "  'Migration': {'likelihood': 'low',\n",
       "   'potential': 'middle',\n",
       "   'certainty': 'middle'},\n",
       "  'Reproduction': {'likelihood': 'low',\n",
       "   'potential': 'middle',\n",
       "   'certainty': 'middle'},\n",
       "  'Aggregation': {'likelihood': 'low',\n",
       "   'potential': 'low',\n",
       "   'certainty': 'high'},\n",
       "  'Aggression': {'likelihood': 'low',\n",
       "   'potential': 'low',\n",
       "   'certainty': 'middle'},\n",
       "  'Substrate': {'likelihood': 'low',\n",
       "   'potential': 'high',\n",
       "   'certainty': 'middle'},\n",
       "  'Stress': {'likelihood': 'low',\n",
       "   'potential': 'middle',\n",
       "   'certainty': 'middle'},\n",
       "  'Malformation': {'likelihood': 'nofindings',\n",
       "   'potential': 'unclear',\n",
       "   'certainty': 'nofindings'},\n",
       "  'Slaughter': {'likelihood': 'unclear',\n",
       "   'potential': 'low',\n",
       "   'certainty': 'middle'},\n",
       "  'FishEthoScore': {'likelihood': 0.0, 'potential': 1.0, 'certainty': 3.0}}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_species_with_short_profiles(species_with_summaries_shortened[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it looks like it's much more difficult to grab the general remarks than I thought it would be;\n",
    "# I'm starting to think that's rendered dynamically. Let's clean everything up and wrap up, and \n",
    "# worse comes to worse we can do a little manual data cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tying everything together**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are relative paths - running the script from a different location may produce surprising results.\n",
    "MAIN_DIR = \"..\"\n",
    "DATA_DIR = os.path.join(MAIN_DIR, \"data\")\n",
    "IMG_DIR = os.path.join(DATA_DIR, \"images\")\n",
    "\n",
    "FISH_BASE_ADDR = \"http://fishethobase.net\"\n",
    "DB_ADDR = FISH_BASE_ADDR + \"/db\"\n",
    "S_PAUSE = 2 # how many seconds to pause in between requests\n",
    "\n",
    "REQ_SUCCESS = 200 # success status code\n",
    "\n",
    "def get_species_data():\n",
    "    soup = get_soup(DB_ADDR)\n",
    "    species_soups = get_species_soups(soup)\n",
    "    species_dicts = list(map(get_species_dict, species_soups))\n",
    "    return species_dicts\n",
    "\n",
    "def get_species_soups(db_soup):\n",
    "    return db_soup.find(class_=\"speciestree-sub\").find_all(attrs={\"class\": \"speciestree-intern\"})\n",
    "\n",
    "def get_species_dict(species_soup):\n",
    "    print(\"\\n***** Collecting species dict *****\")\n",
    "    \n",
    "    species_dict = dict()\n",
    "    add_summary_link(species_soup, species_dict)\n",
    "    add_names(species_soup, species_dict)\n",
    "    \n",
    "    if \"link_summary\" not in species_dict: return\n",
    "    summary_soup = get_soup(species_dict[\"link_summary\"])\n",
    "    if not summary_soup: return\n",
    "    \n",
    "    add_picture(summary_soup, species_dict)\n",
    "    add_description(summary_soup, species_dict)\n",
    "    \n",
    "    profile_address = species_dict[\"link_summary\"].rstrip(\"/\") + \"/shortprofile/\"\n",
    "    profile_soup = get_soup(profile_address)\n",
    "    if not profile_soup: return\n",
    "    species_dict[\"link_profile\"] = profile_address\n",
    "    \n",
    "    add_short_profile(profile_soup, species_dict)\n",
    "    \n",
    "    print(\"***** Finished with species dict *****\")\n",
    "    return species_dict\n",
    "\n",
    "## Accumulator helper functions\n",
    "\n",
    "def add_summary_link(species_soup, species_dict):\n",
    "    pattern = re.compile(\"/db/[0-9]+/?\")\n",
    "    raw_address = species_soup.get(\"href\")\n",
    "    if not pattern.match(raw_address):\n",
    "        print(\"=> (!!) Can't parse raw address:\", raw_address)\n",
    "        return\n",
    "    link = FISH_BASE_ADDR + raw_address\n",
    "    species_dict[\"link_summary\"] = link\n",
    "    print(\"=> Added summary link\")\n",
    "\n",
    "def add_names(species_soup, species_dict):\n",
    "    pattern = re.compile(\"[A-Za-z, ]+\\([A-Za-z() ]+\\)\")\n",
    "    name_text = species_soup.get_text()\n",
    "    if not pattern.match(name_text):\n",
    "        print(\"=> (!!) Unexpected name format:\", name_text)\n",
    "        return\n",
    "    clean_name = lambda n: n.strip().strip(\"(\").strip(\")\") # isn't technically correct, I know\n",
    "    latin_name, english_name = tuple(map(clean_name, name_text.split(\"(\", 1)))\n",
    "    \n",
    "    species_dict[\"name_latin\"] = latin_name\n",
    "    species_dict[\"name_english\"] = english_name\n",
    "    species_dict[\"sp_id\"] = re.sub(\"\\W\", \"\", english_name).lower()\n",
    "    print(\"=> Added names\")\n",
    "\n",
    "def add_picture(summary_soup, species_dict):\n",
    "    picture = summary_soup.find(id=\"species_picture\")\n",
    "    if not picture:\n",
    "        print(\"=> (!!) Can't find picture\")\n",
    "        return\n",
    "    \n",
    "    img = picture.find(\"img\")\n",
    "    img_link = FISH_BASE_ADDR + \"/\" + img[\"src\"].lstrip(\"/\")\n",
    "    img_extension = img_link.split(\".\")[-1] # super hacky\n",
    "    filename = species_dict[\"sp_id\"] + \".\" + img_extension\n",
    "    filepath = os.path.join(IMG_DIR, filename)\n",
    "    \n",
    "    urllib.request.urlretrieve(img_link, filepath)\n",
    "    \n",
    "    species_dict[\"filename_image\"] = filename\n",
    "    print(\"=> Added picture\")\n",
    "\n",
    "def add_description(summary_soup, species_dict):\n",
    "    summary_box = summary_soup.find(class_=\"feb-content-box\")\n",
    "    if not summary_box:\n",
    "        print(\"=> (!!) Can't find summary\")\n",
    "        return\n",
    "    \n",
    "    description = \"\\n\".join([p.get_text() for p in summary_box.find_all(\"p\")])\n",
    "    species_dict[\"description\"] = description\n",
    "    print(\"=> Added description\")\n",
    "\n",
    "def add_short_profile(profile_soup, species_dict):\n",
    "    table = profile_soup.find(\"table\", attrs={\"class\": \"shortprofile\"})\n",
    "    if not table:\n",
    "        print(\"=> (!!) Can't find profile table\")\n",
    "        return\n",
    "    \n",
    "    data = {}\n",
    "    variables = [\"likelihood\", \"potential\", \"certainty\"]\n",
    "    rows = table.find_all(\"tr\")[1:]\n",
    "    \n",
    "    for row in rows[:-1]:\n",
    "        criteria, data_dict = get_profile_row_data(\n",
    "            row, variables,\n",
    "            get_col_data=lambda col: col[\"class\"][0],\n",
    "            data_start_index=1)\n",
    "        data[criteria] = data_dict\n",
    "    \n",
    "    score_criteria, score_dict = get_profile_row_data(\n",
    "        row, variables,\n",
    "        get_col_data=lambda col: col.get_text())\n",
    "    data[score_criteria] = score_dict\n",
    "    \n",
    "    species_dict[\"etho_scores\"] = data\n",
    "    print(\"=> Added profile table\")\n",
    "\n",
    "def get_profile_row_data(row, variables, get_col_data, data_start_index=0):\n",
    "    columns = row.find_all(\"td\")[data_start_index:]\n",
    "    criteria = columns[0].get_text()\n",
    "    values = map(get_col_data, columns[1:])\n",
    "    return criteria, dict(zip(variables, values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded page: http://fishethobase.net/db\n",
      "\n",
      "***** Collecting species dict *****\n",
      "=> Added summary link\n",
      "=> Added names\n",
      "Loaded page: http://fishethobase.net/db/28/\n",
      "=> (!!) Can't find picture\n",
      "=> Added description\n",
      "Loaded page: http://fishethobase.net/db/28/shortprofile/\n",
      "=> Added profile table\n",
      "***** Finished with species dict *****\n",
      "\n",
      "***** Collecting species dict *****\n",
      "=> Added summary link\n",
      "=> Added names\n",
      "Loaded page: http://fishethobase.net/db/21/\n",
      "=> (!!) Can't find picture\n",
      "=> Added description\n",
      "Loaded page: http://fishethobase.net/db/21/shortprofile/\n",
      "=> Added profile table\n",
      "***** Finished with species dict *****\n",
      "\n",
      "***** Collecting species dict *****\n",
      "=> Added summary link\n",
      "=> Added names\n",
      "Loaded page: http://fishethobase.net/db/34/\n",
      "=> Added picture\n",
      "=> Added description\n",
      "Loaded page: http://fishethobase.net/db/34/shortprofile/\n",
      "=> Added profile table\n",
      "***** Finished with species dict *****\n",
      "\n",
      "***** Collecting species dict *****\n",
      "=> Added summary link\n",
      "=> Added names\n",
      "Loaded page: http://fishethobase.net/db/2/\n",
      "=> Added picture\n",
      "=> Added description\n",
      "Loaded page: http://fishethobase.net/db/2/shortprofile/\n",
      "=> Added profile table\n",
      "***** Finished with species dict *****\n",
      "\n",
      "***** Collecting species dict *****\n",
      "=> Added summary link\n",
      "=> Added names\n",
      "Loaded page: http://fishethobase.net/db/3/\n",
      "=> Added picture\n",
      "=> Added description\n",
      "Loaded page: http://fishethobase.net/db/3/shortprofile/\n",
      "=> Added profile table\n",
      "***** Finished with species dict *****\n",
      "\n",
      "***** Collecting species dict *****\n",
      "=> Added summary link\n",
      "=> Added names\n",
      "Loaded page: http://fishethobase.net/db/4/\n",
      "=> Added picture\n",
      "=> Added description\n",
      "Loaded page: http://fishethobase.net/db/4/shortprofile/\n",
      "=> Added profile table\n",
      "***** Finished with species dict *****\n",
      "\n",
      "***** Collecting species dict *****\n",
      "=> Added summary link\n",
      "=> Added names\n",
      "Loaded page: http://fishethobase.net/db/6/\n",
      "=> Added picture\n",
      "=> Added description\n",
      "Loaded page: http://fishethobase.net/db/6/shortprofile/\n",
      "=> Added profile table\n",
      "***** Finished with species dict *****\n",
      "\n",
      "***** Collecting species dict *****\n",
      "=> Added summary link\n",
      "=> Added names\n",
      "Loaded page: http://fishethobase.net/db/5/\n",
      "=> Added picture\n",
      "=> Added description\n",
      "Loaded page: http://fishethobase.net/db/5/shortprofile/\n",
      "=> Added profile table\n",
      "***** Finished with species dict *****\n",
      "\n",
      "***** Collecting species dict *****\n",
      "=> Added summary link\n",
      "=> Added names\n",
      "Loaded page: http://fishethobase.net/db/7/\n",
      "=> Added picture\n",
      "=> Added description\n",
      "Loaded page: http://fishethobase.net/db/7/shortprofile/\n",
      "=> Added profile table\n",
      "***** Finished with species dict *****\n",
      "\n",
      "***** Collecting species dict *****\n",
      "=> Added summary link\n",
      "=> Added names\n",
      "Loaded page: http://fishethobase.net/db/53/\n",
      "=> Added picture\n",
      "=> Added description\n",
      "Loaded page: http://fishethobase.net/db/53/shortprofile/\n",
      "=> Added profile table\n",
      "***** Finished with species dict *****\n",
      "\n",
      "***** Collecting species dict *****\n",
      "=> Added summary link\n",
      "=> Added names\n",
      "Loaded page: http://fishethobase.net/db/61/\n",
      "=> (!!) Can't find picture\n",
      "=> (!!) Can't find summary\n",
      "Loaded page: http://fishethobase.net/db/61/shortprofile/\n",
      "=> Added profile table\n",
      "***** Finished with species dict *****\n",
      "\n",
      "***** Collecting species dict *****\n",
      "=> Added summary link\n",
      "=> Added names\n",
      "Loaded page: http://fishethobase.net/db/11/\n",
      "=> Added picture\n",
      "=> Added description\n",
      "Loaded page: http://fishethobase.net/db/11/shortprofile/\n",
      "=> Added profile table\n",
      "***** Finished with species dict *****\n",
      "\n",
      "***** Collecting species dict *****\n",
      "=> Added summary link\n",
      "=> Added names\n",
      "Loaded page: http://fishethobase.net/db/12/\n",
      "=> Added picture\n",
      "=> Added description\n",
      "Loaded page: http://fishethobase.net/db/12/shortprofile/\n",
      "=> Added profile table\n",
      "***** Finished with species dict *****\n",
      "\n",
      "***** Collecting species dict *****\n",
      "=> Added summary link\n",
      "=> Added names\n",
      "Loaded page: http://fishethobase.net/db/17/\n",
      "=> Added picture\n",
      "=> Added description\n",
      "Loaded page: http://fishethobase.net/db/17/shortprofile/\n",
      "=> Added profile table\n",
      "***** Finished with species dict *****\n",
      "\n",
      "***** Collecting species dict *****\n",
      "=> Added summary link\n",
      "=> Added names\n",
      "Loaded page: http://fishethobase.net/db/22/\n",
      "=> Added picture\n",
      "=> Added description\n",
      "Loaded page: http://fishethobase.net/db/22/shortprofile/\n",
      "=> Added profile table\n",
      "***** Finished with species dict *****\n",
      "\n",
      "***** Collecting species dict *****\n",
      "=> Added summary link\n",
      "=> Added names\n",
      "Loaded page: http://fishethobase.net/db/26/\n",
      "=> Added picture\n",
      "=> Added description\n",
      "Loaded page: http://fishethobase.net/db/26/shortprofile/\n",
      "=> Added profile table\n",
      "***** Finished with species dict *****\n",
      "\n",
      "***** Collecting species dict *****\n",
      "=> Added summary link\n",
      "=> Added names\n",
      "Loaded page: http://fishethobase.net/db/45/\n",
      "=> Added picture\n",
      "=> Added description\n",
      "Loaded page: http://fishethobase.net/db/45/shortprofile/\n",
      "=> Added profile table\n",
      "***** Finished with species dict *****\n",
      "\n",
      "***** Collecting species dict *****\n",
      "=> Added summary link\n",
      "=> Added names\n",
      "Loaded page: http://fishethobase.net/db/46/\n",
      "=> Added picture\n",
      "=> Added description\n",
      "Loaded page: http://fishethobase.net/db/46/shortprofile/\n",
      "=> Added profile table\n",
      "***** Finished with species dict *****\n",
      "\n",
      "***** Collecting species dict *****\n",
      "=> Added summary link\n",
      "=> Added names\n",
      "Loaded page: http://fishethobase.net/db/31/\n",
      "=> Added picture\n",
      "=> Added description\n",
      "Loaded page: http://fishethobase.net/db/31/shortprofile/\n",
      "=> Added profile table\n",
      "***** Finished with species dict *****\n",
      "\n",
      "***** Collecting species dict *****\n",
      "=> Added summary link\n",
      "=> Added names\n",
      "Loaded page: http://fishethobase.net/db/20/\n",
      "=> Added picture\n",
      "=> Added description\n",
      "Loaded page: http://fishethobase.net/db/20/shortprofile/\n",
      "=> Added profile table\n",
      "***** Finished with species dict *****\n",
      "\n",
      "***** Collecting species dict *****\n",
      "=> Added summary link\n",
      "=> Added names\n",
      "Loaded page: http://fishethobase.net/db/14/\n",
      "=> Added picture\n",
      "=> Added description\n",
      "Loaded page: http://fishethobase.net/db/14/shortprofile/\n",
      "=> Added profile table\n",
      "***** Finished with species dict *****\n",
      "\n",
      "***** Collecting species dict *****\n",
      "=> Added summary link\n",
      "=> Added names\n",
      "Loaded page: http://fishethobase.net/db/35/\n",
      "=> Added picture\n",
      "=> Added description\n",
      "Loaded page: http://fishethobase.net/db/35/shortprofile/\n",
      "=> Added profile table\n",
      "***** Finished with species dict *****\n",
      "\n",
      "***** Collecting species dict *****\n",
      "=> Added summary link\n",
      "=> Added names\n",
      "Loaded page: http://fishethobase.net/db/42/\n",
      "=> Added picture\n",
      "=> Added description\n",
      "Loaded page: http://fishethobase.net/db/42/shortprofile/\n",
      "=> Added profile table\n",
      "***** Finished with species dict *****\n",
      "\n",
      "***** Collecting species dict *****\n",
      "=> Added summary link\n",
      "=> Added names\n",
      "Loaded page: http://fishethobase.net/db/13/\n",
      "=> Added picture\n",
      "=> Added description\n",
      "Loaded page: http://fishethobase.net/db/13/shortprofile/\n",
      "=> Added profile table\n",
      "***** Finished with species dict *****\n",
      "\n",
      "***** Collecting species dict *****\n",
      "=> Added summary link\n",
      "=> Added names\n",
      "Loaded page: http://fishethobase.net/db/36/\n",
      "=> Added picture\n",
      "=> Added description\n",
      "Loaded page: http://fishethobase.net/db/36/shortprofile/\n",
      "=> Added profile table\n",
      "***** Finished with species dict *****\n",
      "\n",
      "***** Collecting species dict *****\n",
      "=> Added summary link\n",
      "=> Added names\n",
      "Loaded page: http://fishethobase.net/db/38/\n",
      "=> Added picture\n",
      "=> Added description\n",
      "Loaded page: http://fishethobase.net/db/38/shortprofile/\n",
      "=> Added profile table\n",
      "***** Finished with species dict *****\n",
      "\n",
      "***** Collecting species dict *****\n",
      "=> Added summary link\n",
      "=> Added names\n",
      "Loaded page: http://fishethobase.net/db/8/\n",
      "=> Added picture\n",
      "=> Added description\n",
      "Loaded page: http://fishethobase.net/db/8/shortprofile/\n",
      "=> Added profile table\n",
      "***** Finished with species dict *****\n",
      "\n",
      "***** Collecting species dict *****\n",
      "=> Added summary link\n",
      "=> Added names\n",
      "Loaded page: http://fishethobase.net/db/50/\n",
      "=> Added picture\n",
      "=> Added description\n",
      "Loaded page: http://fishethobase.net/db/50/shortprofile/\n",
      "=> Added profile table\n",
      "***** Finished with species dict *****\n",
      "\n",
      "***** Collecting species dict *****\n",
      "=> Added summary link\n",
      "=> Added names\n",
      "Loaded page: http://fishethobase.net/db/16/\n",
      "=> Added picture\n",
      "=> Added description\n",
      "Loaded page: http://fishethobase.net/db/16/shortprofile/\n",
      "=> Added profile table\n",
      "***** Finished with species dict *****\n",
      "\n",
      "***** Collecting species dict *****\n",
      "=> Added summary link\n",
      "=> Added names\n",
      "Loaded page: http://fishethobase.net/db/15/\n",
      "=> Added picture\n",
      "=> Added description\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded page: http://fishethobase.net/db/15/shortprofile/\n",
      "=> Added profile table\n",
      "***** Finished with species dict *****\n",
      "\n",
      "***** Collecting species dict *****\n",
      "=> Added summary link\n",
      "=> Added names\n",
      "Loaded page: http://fishethobase.net/db/32/\n",
      "=> (!!) Can't find picture\n",
      "=> Added description\n",
      "Loaded page: http://fishethobase.net/db/32/shortprofile/\n",
      "=> Added profile table\n",
      "***** Finished with species dict *****\n",
      "\n",
      "***** Collecting species dict *****\n",
      "=> Added summary link\n",
      "=> Added names\n",
      "Loaded page: http://fishethobase.net/db/49/\n",
      "=> Added picture\n",
      "=> Added description\n",
      "Loaded page: http://fishethobase.net/db/49/shortprofile/\n",
      "=> Added profile table\n",
      "***** Finished with species dict *****\n",
      "\n",
      "***** Collecting species dict *****\n",
      "=> Added summary link\n",
      "=> Added names\n",
      "Loaded page: http://fishethobase.net/db/18/\n",
      "=> Added picture\n",
      "=> Added description\n",
      "Loaded page: http://fishethobase.net/db/18/shortprofile/\n",
      "=> Added profile table\n",
      "***** Finished with species dict *****\n",
      "\n",
      "***** Collecting species dict *****\n",
      "=> Added summary link\n",
      "=> Added names\n",
      "Loaded page: http://fishethobase.net/db/43/\n",
      "=> Added picture\n",
      "=> Added description\n",
      "Loaded page: http://fishethobase.net/db/43/shortprofile/\n",
      "=> Added profile table\n",
      "***** Finished with species dict *****\n",
      "\n",
      "***** Collecting species dict *****\n",
      "=> Added summary link\n",
      "=> Added names\n",
      "Loaded page: http://fishethobase.net/db/48/\n",
      "=> Added picture\n",
      "=> Added description\n",
      "Loaded page: http://fishethobase.net/db/48/shortprofile/\n",
      "=> Added profile table\n",
      "***** Finished with species dict *****\n",
      "\n",
      "***** Collecting species dict *****\n",
      "=> Added summary link\n",
      "=> Added names\n",
      "Loaded page: http://fishethobase.net/db/47/\n",
      "=> Added picture\n",
      "=> Added description\n",
      "Loaded page: http://fishethobase.net/db/47/shortprofile/\n",
      "=> Added profile table\n",
      "***** Finished with species dict *****\n",
      "\n",
      "***** Collecting species dict *****\n",
      "=> Added summary link\n",
      "=> Added names\n",
      "Loaded page: http://fishethobase.net/db/29/\n",
      "=> Added picture\n",
      "=> Added description\n",
      "Loaded page: http://fishethobase.net/db/29/shortprofile/\n",
      "=> Added profile table\n",
      "***** Finished with species dict *****\n",
      "\n",
      "***** Collecting species dict *****\n",
      "=> Added summary link\n",
      "=> Added names\n",
      "Loaded page: http://fishethobase.net/db/30/\n",
      "=> Added picture\n",
      "=> Added description\n",
      "Loaded page: http://fishethobase.net/db/30/shortprofile/\n",
      "=> Added profile table\n",
      "***** Finished with species dict *****\n",
      "\n",
      "***** Collecting species dict *****\n",
      "=> Added summary link\n",
      "=> Added names\n",
      "Loaded page: http://fishethobase.net/db/1/\n",
      "=> Added picture\n",
      "=> Added description\n",
      "Loaded page: http://fishethobase.net/db/1/shortprofile/\n",
      "=> Added profile table\n",
      "***** Finished with species dict *****\n",
      "\n",
      "***** Collecting species dict *****\n",
      "=> Added summary link\n",
      "=> Added names\n",
      "Loaded page: http://fishethobase.net/db/40/\n",
      "=> Added picture\n",
      "=> Added description\n",
      "Loaded page: http://fishethobase.net/db/40/shortprofile/\n",
      "=> Added profile table\n",
      "***** Finished with species dict *****\n",
      "\n",
      "***** Collecting species dict *****\n",
      "=> Added summary link\n",
      "=> Added names\n",
      "Loaded page: http://fishethobase.net/db/41/\n",
      "=> Added picture\n",
      "=> Added description\n",
      "Loaded page: http://fishethobase.net/db/41/shortprofile/\n",
      "=> Added profile table\n",
      "***** Finished with species dict *****\n",
      "\n",
      "***** Collecting species dict *****\n",
      "=> Added summary link\n",
      "=> Added names\n",
      "Loaded page: http://fishethobase.net/db/51/\n",
      "=> Added picture\n",
      "=> Added description\n",
      "Loaded page: http://fishethobase.net/db/51/shortprofile/\n",
      "=> Added profile table\n",
      "***** Finished with species dict *****\n",
      "\n",
      "***** Collecting species dict *****\n",
      "=> Added summary link\n",
      "=> Added names\n",
      "Loaded page: http://fishethobase.net/db/10/\n",
      "=> Added picture\n",
      "=> Added description\n",
      "Loaded page: http://fishethobase.net/db/10/shortprofile/\n",
      "=> Added profile table\n",
      "***** Finished with species dict *****\n",
      "\n",
      "***** Collecting species dict *****\n",
      "=> Added summary link\n",
      "=> Added names\n",
      "Loaded page: http://fishethobase.net/db/33/\n",
      "=> Added picture\n",
      "=> Added description\n",
      "Loaded page: http://fishethobase.net/db/33/shortprofile/\n",
      "=> Added profile table\n",
      "***** Finished with species dict *****\n"
     ]
    }
   ],
   "source": [
    "all_data = get_species_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'link_summary': 'http://fishethobase.net/db/28/',\n",
       " 'name_latin': 'Octopus vulgaris',\n",
       " 'name_english': 'Common octopus',\n",
       " 'sp_id': 'commonoctopus',\n",
       " 'description': 'Octopus vulgaris has recently aroused much interest in aquaculture, considered suitable for large-scale production given its commercial value, its fecundity, rapid growth, high protein content, and high feed conversion rate. The main problem, however, is the high mortality rate observed during paralarval rearing, making successful juvenile settlement still very difficult to achieve. Unfortunately, despite the high knowledge on the biology and ethology of this species, there are many other aspects to be solved from a welfare perspective. For instance, the current farming systems result in high stress in O. vulgaris due to spatial constraint, high densities and sociability, which consequently increase aggression (cannibalism and autophagy) at different life stages. In addition, octopus skin is particularly sensitive and can be easily damaged during handling, transportation or stressful confinement conditions. A humane slaughtering protocol is not yet established, since the nature and degree of any suffering during current practices are unknown. O. vulgaris appears capable of experiencing pain and suffering, exhibits cognitive complexity and sophisticated behavioural patterns which can be interpreted and serve as indicator of the welfare status.',\n",
       " 'link_profile': 'http://fishethobase.net/db/28/shortprofile/',\n",
       " 'etho_scores': {'Home range': {'likelihood': 'low',\n",
       "   'potential': 'low',\n",
       "   'certainty': 'high'},\n",
       "  'Depth range': {'likelihood': 'low',\n",
       "   'potential': 'middle',\n",
       "   'certainty': 'high'},\n",
       "  'Migration': {'likelihood': 'low',\n",
       "   'potential': 'middle',\n",
       "   'certainty': 'middle'},\n",
       "  'Reproduction': {'likelihood': 'low',\n",
       "   'potential': 'middle',\n",
       "   'certainty': 'middle'},\n",
       "  'Aggregation': {'likelihood': 'low',\n",
       "   'potential': 'low',\n",
       "   'certainty': 'high'},\n",
       "  'Aggression': {'likelihood': 'low',\n",
       "   'potential': 'low',\n",
       "   'certainty': 'middle'},\n",
       "  'Substrate': {'likelihood': 'low',\n",
       "   'potential': 'high',\n",
       "   'certainty': 'middle'},\n",
       "  'Stress': {'likelihood': 'low',\n",
       "   'potential': 'middle',\n",
       "   'certainty': 'middle'},\n",
       "  'Malformation': {'likelihood': 'nofindings',\n",
       "   'potential': 'unclear',\n",
       "   'certainty': 'nofindings'},\n",
       "  'Slaughter': {'likelihood': 'unclear',\n",
       "   'potential': 'low',\n",
       "   'certainty': 'middle'},\n",
       "  '10': {'likelihood': 'Slaughter', 'potential': '?', 'certainty': ''}}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "OUTPUT_FILENAME = \"fishdb.json\"\n",
    "OUTPUT_FP = os.path.join(DATA_DIR, OUTPUT_FILENAME)\n",
    "with open(OUTPUT_FP, \"w\") as outfile:\n",
    "    json.dump(all_data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
